{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\n",
    "\n",
    "The presented code is not optimized, it serves an educational purpose. It is written for CPU, it uses only fully-connected networks and an extremely simplistic dataset. However, it contains all components that can help to understand how an autoregressive model (ARM) works, and it should be rather easy to extend it to more sophisticated models. This code could be run almost on any laptop/PC, and it takes a couple of minutes top to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in $\\{0, 1, \\ldots, 16\\}$.\n",
    "\n",
    "The goal of using this dataset is that everyone can run it on a laptop, without any gpu etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the blogpost for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A causal 1D convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, A=False, **kwargs):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # attributes:\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.A = A\n",
    "        \n",
    "        self.padding = (kernel_size - 1) * dilation + A * 1\n",
    "\n",
    "        # module:\n",
    "        self.conv1d = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                      kernel_size, stride=1,\n",
    "                                      padding=0,\n",
    "                                      dilation=dilation,\n",
    "                                      **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x, (self.padding, 0))\n",
    "        conv1d_out = self.conv1d(x)\n",
    "        if self.A:\n",
    "            return conv1d_out[:, :, : -1]\n",
    "        else:\n",
    "            return conv1d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1.e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARM(nn.Module):\n",
    "    def __init__(self, net, D=2, num_vals=256):\n",
    "        super(ARM, self).__init__()\n",
    "\n",
    "        print('ARM by JT.')\n",
    "\n",
    "        self.net = net\n",
    "        self.num_vals = num_vals\n",
    "        self.D = D\n",
    "\n",
    "    def f(self, x):\n",
    "        h = self.net(x.unsqueeze(1))\n",
    "\n",
    "        h = h.permute(0, 2, 1)\n",
    "        p = torch.softmax(h, 2)\n",
    "        return p\n",
    "        \n",
    "    def forward(self, x, reduction='avg'):\n",
    "        if reduction == 'avg':\n",
    "            return -(self.log_prob(x).mean())\n",
    "        elif reduction == 'sum':\n",
    "            return -(self.log_prob(x).sum())\n",
    "        else:\n",
    "            raise ValueError('reduction could be either `avg` or `sum`.')\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        mu_d = self.f(x)\n",
    "        log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "        \n",
    "        return log_p\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        x_new = torch.zeros((batch_size, self.D))\n",
    "\n",
    "        for d in range(self.D):\n",
    "            p = self.f(x_new)\n",
    "            x_new_d = torch.multinomial(p[:, d, :], num_samples=1)\n",
    "            x_new[:, d] = x_new_d[:,0]\n",
    "\n",
    "        return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions: training, evaluation, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rather self-explanatory, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, 'dequantization'):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 64   # input dimension\n",
    "# M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "# lr = 1e-3 # learning rate\n",
    "# num_epochs = 1000 # max. number of epochs\n",
    "# max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped\n",
    "\n",
    "D = 64   # input dimension\n",
    "M = 64  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 100 # max. number of epochs\n",
    "max_patience = 5 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "    CausalConv1d-1         [1, 64, 64]             512             512\n",
      "       LeakyReLU-2         [1, 64, 64]               0               0\n",
      "    CausalConv1d-3         [1, 64, 64]          28,736          28,736\n",
      "       LeakyReLU-4         [1, 64, 64]               0               0\n",
      "    CausalConv1d-5         [1, 64, 64]          28,736          28,736\n",
      "       LeakyReLU-6         [1, 64, 64]               0               0\n",
      "    CausalConv1d-7         [1, 17, 64]           7,633           7,633\n",
      "=======================================================================\n",
      "Total params: 65,617\n",
      "Trainable params: 65,617\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "num_vals = 17\n",
    "\n",
    "kernel = 7\n",
    "\n",
    "net = nn.Sequential(\n",
    "    CausalConv1d(in_channels=1, out_channels=M, dilation=1, kernel_size=kernel, A=True, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=num_vals, dilation=1, kernel_size=kernel, A=False, bias=True))\n",
    "\n",
    "model = ARM(net, D=D, num_vals=num_vals)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))\n",
    "\n",
    "model_label = \"vanilla\"\n",
    "experiment = f\"arm-{model_label}_{M}-neurons_{lr:.1e}-lr_{num_epochs}-max-epochs\"\n",
    "\n",
    "result_dir = f'results/{experiment}/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = f'arm-{model_label}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play! Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=122.24587053571429\n",
      "saved!\n",
      "Epoch: 1, val nll=115.21426688058035\n",
      "saved!\n",
      "Epoch: 2, val nll=112.75198311941965\n",
      "saved!\n",
      "Epoch: 3, val nll=111.19076590401785\n",
      "saved!\n",
      "Epoch: 4, val nll=109.9572802734375\n",
      "saved!\n",
      "Epoch: 5, val nll=108.91850376674107\n",
      "saved!\n",
      "Epoch: 6, val nll=107.84147112165178\n",
      "saved!\n",
      "Epoch: 7, val nll=106.70080705915178\n",
      "saved!\n",
      "Epoch: 8, val nll=105.43297712053571\n",
      "saved!\n",
      "Epoch: 9, val nll=104.14315011160714\n",
      "saved!\n",
      "Epoch: 10, val nll=102.70897042410714\n",
      "saved!\n",
      "Epoch: 11, val nll=101.45714704241071\n",
      "saved!\n",
      "Epoch: 12, val nll=100.37817940848214\n",
      "saved!\n",
      "Epoch: 13, val nll=99.54991908482143\n",
      "saved!\n",
      "Epoch: 14, val nll=98.73875139508928\n",
      "saved!\n",
      "Epoch: 15, val nll=97.73501534598215\n",
      "saved!\n",
      "Epoch: 16, val nll=97.04239536830357\n",
      "saved!\n",
      "Epoch: 17, val nll=96.53377162388392\n",
      "saved!\n",
      "Epoch: 18, val nll=95.92029157366072\n",
      "saved!\n",
      "Epoch: 19, val nll=95.51119489397321\n",
      "saved!\n",
      "Epoch: 20, val nll=94.97449846540178\n",
      "saved!\n",
      "Epoch: 21, val nll=94.63533482142857\n",
      "saved!\n",
      "Epoch: 22, val nll=94.10585867745536\n",
      "saved!\n",
      "Epoch: 23, val nll=93.98363420758929\n",
      "saved!\n",
      "Epoch: 24, val nll=93.65577427455356\n",
      "saved!\n",
      "Epoch: 25, val nll=93.374208984375\n",
      "saved!\n",
      "Epoch: 26, val nll=93.06364118303571\n",
      "saved!\n",
      "Epoch: 27, val nll=92.68555943080356\n",
      "saved!\n",
      "Epoch: 28, val nll=92.67453822544643\n",
      "saved!\n",
      "Epoch: 29, val nll=92.60943568638393\n",
      "saved!\n",
      "Epoch: 30, val nll=92.30602678571428\n",
      "saved!\n",
      "Epoch: 31, val nll=92.07054827008929\n",
      "saved!\n",
      "Epoch: 32, val nll=92.25319684709821\n",
      "Epoch: 33, val nll=91.67786272321429\n",
      "saved!\n",
      "Epoch: 34, val nll=91.77796735491071\n",
      "Epoch: 35, val nll=91.405791015625\n",
      "saved!\n",
      "Epoch: 36, val nll=91.68723981584822\n",
      "Epoch: 37, val nll=91.13969796316964\n",
      "saved!\n",
      "Epoch: 38, val nll=91.19190638950893\n",
      "Epoch: 39, val nll=91.44556012834822\n",
      "Epoch: 40, val nll=90.99547223772322\n",
      "saved!\n",
      "Epoch: 41, val nll=91.0785595703125\n",
      "Epoch: 42, val nll=90.66132114955357\n",
      "saved!\n",
      "Epoch: 43, val nll=90.85242745535714\n",
      "Epoch: 44, val nll=90.561669921875\n",
      "saved!\n",
      "Epoch: 45, val nll=90.54002162388393\n",
      "saved!\n",
      "Epoch: 46, val nll=90.27501883370536\n",
      "saved!\n",
      "Epoch: 47, val nll=90.38125418526786\n",
      "Epoch: 48, val nll=90.59013741629464\n",
      "Epoch: 49, val nll=90.11284319196429\n",
      "saved!\n",
      "Epoch: 50, val nll=90.18498186383928\n",
      "Epoch: 51, val nll=90.26965262276785\n",
      "Epoch: 52, val nll=90.09609444754464\n",
      "saved!\n",
      "Epoch: 53, val nll=89.94261509486607\n",
      "saved!\n",
      "Epoch: 54, val nll=89.87827008928572\n",
      "saved!\n",
      "Epoch: 55, val nll=89.91530622209821\n",
      "Epoch: 56, val nll=89.645029296875\n",
      "saved!\n",
      "Epoch: 57, val nll=89.62868233816964\n",
      "saved!\n",
      "Epoch: 58, val nll=89.63056291852679\n",
      "Epoch: 59, val nll=89.67127371651786\n",
      "Epoch: 60, val nll=89.69889369419643\n",
      "Epoch: 61, val nll=89.782978515625\n",
      "Epoch: 62, val nll=89.5288818359375\n",
      "saved!\n",
      "Epoch: 63, val nll=89.56732352120535\n",
      "Epoch: 64, val nll=89.64895577566965\n",
      "Epoch: 65, val nll=89.45833914620536\n",
      "saved!\n",
      "Epoch: 66, val nll=89.51901436941964\n",
      "Epoch: 67, val nll=89.45089215959821\n",
      "saved!\n",
      "Epoch: 68, val nll=89.42123744419642\n",
      "saved!\n",
      "Epoch: 69, val nll=89.57901925223214\n",
      "Epoch: 70, val nll=89.30857840401785\n",
      "saved!\n",
      "Epoch: 71, val nll=89.13559291294642\n",
      "saved!\n",
      "Epoch: 72, val nll=89.21737583705357\n",
      "Epoch: 73, val nll=89.19666434151786\n",
      "Epoch: 74, val nll=89.27518415178571\n",
      "Epoch: 75, val nll=89.29764787946428\n",
      "Epoch: 76, val nll=89.23113211495536\n",
      "Epoch: 77, val nll=89.0304345703125\n",
      "saved!\n",
      "Epoch: 78, val nll=89.00259556361607\n",
      "saved!\n",
      "Epoch: 79, val nll=89.15502720424107\n",
      "Epoch: 80, val nll=89.2000732421875\n",
      "Epoch: 81, val nll=89.08006138392857\n",
      "Epoch: 82, val nll=89.01402971540179\n",
      "Epoch: 83, val nll=89.01939104352678\n",
      "Epoch: 84, val nll=88.94025809151786\n",
      "saved!\n",
      "Epoch: 85, val nll=89.20838936941965\n",
      "Epoch: 86, val nll=89.25089146205357\n",
      "Epoch: 87, val nll=88.86695103236607\n",
      "saved!\n",
      "Epoch: 88, val nll=89.14937290736607\n",
      "Epoch: 89, val nll=89.01422084263393\n",
      "Epoch: 90, val nll=89.10131068638393\n",
      "Epoch: 91, val nll=88.91599051339286\n",
      "Epoch: 92, val nll=88.95630231584822\n",
      "Epoch: 93, val nll=88.98825544084822\n"
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(\n",
    "    name=result_dir + name,\n",
    "    max_patience=max_patience,\n",
    "    num_epochs=num_epochs,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    training_loader=training_loader,\n",
    "    val_loader=val_loader,\n",
    ")\n",
    "# save training loss curve for further training comparisons.\n",
    "np.savetxt(fname=f\"{result_dir}nll_per_epoch.csv\", X=nll_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=86.02746281634508\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "    CausalConv1d-1         [1, 64, 64]             512             512\n",
      "       LeakyReLU-2         [1, 64, 64]               0               0\n",
      "    CausalConv1d-3         [1, 64, 64]          28,736          28,736\n",
      "       LeakyReLU-4         [1, 64, 64]               0               0\n",
      "    CausalConv1d-5         [1, 64, 64]          28,736          28,736\n",
      "       LeakyReLU-6         [1, 64, 64]               0               0\n",
      "    CausalConv1d-7         [1, 17, 64]           7,633           7,633\n",
      "=======================================================================\n",
      "Total params: 65,617\n",
      "Trainable params: 65,617\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "Epoch: 0, val nll=122.98001604352679\n",
      "saved!\n",
      "Epoch: 1, val nll=115.76096888950893\n",
      "saved!\n",
      "Epoch: 2, val nll=112.666259765625\n",
      "saved!\n",
      "Epoch: 3, val nll=111.22457240513393\n",
      "saved!\n",
      "Epoch: 4, val nll=109.99372907366072\n",
      "saved!\n",
      "Epoch: 5, val nll=108.87401506696429\n",
      "saved!\n",
      "Epoch: 6, val nll=108.01993303571429\n",
      "saved!\n",
      "Epoch: 7, val nll=106.98870814732143\n",
      "saved!\n",
      "Epoch: 8, val nll=106.01084751674107\n",
      "saved!\n",
      "Epoch: 9, val nll=104.70149972098214\n",
      "saved!\n",
      "Epoch: 10, val nll=103.52030831473215\n",
      "saved!\n",
      "Epoch: 11, val nll=102.191708984375\n",
      "saved!\n",
      "Epoch: 12, val nll=101.26818359375\n",
      "saved!\n",
      "Epoch: 13, val nll=100.26698032924106\n",
      "saved!\n",
      "Epoch: 14, val nll=99.21340959821428\n",
      "saved!\n",
      "Epoch: 15, val nll=98.70556012834821\n",
      "saved!\n",
      "Epoch: 16, val nll=97.83484584263392\n",
      "saved!\n",
      "Epoch: 17, val nll=97.29472028459821\n",
      "saved!\n",
      "Epoch: 18, val nll=96.68500558035714\n",
      "saved!\n",
      "Epoch: 19, val nll=96.09338309151785\n",
      "saved!\n",
      "Epoch: 20, val nll=95.61580915178571\n",
      "saved!\n",
      "Epoch: 21, val nll=94.97893973214286\n",
      "saved!\n",
      "Epoch: 22, val nll=94.4912841796875\n",
      "saved!\n",
      "Epoch: 23, val nll=94.16111118861608\n",
      "saved!\n",
      "Epoch: 24, val nll=93.96616489955358\n",
      "saved!\n",
      "Epoch: 25, val nll=93.47079380580357\n",
      "saved!\n",
      "Epoch: 26, val nll=93.20384626116072\n",
      "saved!\n",
      "Epoch: 27, val nll=93.01839215959822\n",
      "saved!\n",
      "Epoch: 28, val nll=93.20591099330358\n",
      "Epoch: 29, val nll=92.62181012834822\n",
      "saved!\n",
      "Epoch: 30, val nll=92.59999302455357\n",
      "saved!\n",
      "Epoch: 31, val nll=92.34349748883929\n",
      "saved!\n",
      "Epoch: 32, val nll=92.17789899553571\n",
      "saved!\n",
      "Epoch: 33, val nll=91.90300990513393\n",
      "saved!\n",
      "Epoch: 34, val nll=91.91221330915178\n",
      "Epoch: 35, val nll=91.66277064732142\n",
      "saved!\n",
      "Epoch: 36, val nll=91.68864536830357\n",
      "Epoch: 37, val nll=91.59792131696429\n",
      "saved!\n",
      "Epoch: 38, val nll=91.3668896484375\n",
      "saved!\n",
      "Epoch: 39, val nll=91.31054268973215\n",
      "saved!\n",
      "Epoch: 40, val nll=91.32546316964286\n",
      "Epoch: 41, val nll=91.27888044084821\n",
      "saved!\n",
      "Epoch: 42, val nll=91.15127092633928\n",
      "saved!\n",
      "Epoch: 43, val nll=90.76547712053572\n",
      "saved!\n",
      "Epoch: 44, val nll=90.84535295758928\n",
      "Epoch: 45, val nll=90.92465192522322\n",
      "Epoch: 46, val nll=90.56920758928571\n",
      "saved!\n",
      "Epoch: 47, val nll=90.45012486049107\n",
      "saved!\n",
      "Epoch: 48, val nll=90.21098772321429\n",
      "saved!\n",
      "Epoch: 49, val nll=90.4345458984375\n",
      "Epoch: 50, val nll=90.37652762276785\n",
      "Epoch: 51, val nll=90.54811104910715\n",
      "Epoch: 52, val nll=90.13234165736607\n",
      "saved!\n",
      "Epoch: 53, val nll=90.02529575892858\n",
      "saved!\n",
      "Epoch: 54, val nll=90.13971609933036\n",
      "Epoch: 55, val nll=89.99447893415179\n",
      "saved!\n",
      "Epoch: 56, val nll=89.93935965401786\n",
      "saved!\n",
      "Epoch: 57, val nll=90.27675851004464\n",
      "Epoch: 58, val nll=89.83202566964286\n",
      "saved!\n",
      "Epoch: 59, val nll=89.86815359933036\n",
      "Epoch: 60, val nll=89.87429129464286\n",
      "Epoch: 61, val nll=89.61476702008929\n",
      "saved!\n",
      "Epoch: 62, val nll=89.7619921875\n",
      "Epoch: 63, val nll=89.67248186383928\n",
      "Epoch: 64, val nll=89.74856236049108\n",
      "Epoch: 65, val nll=89.508779296875\n",
      "saved!\n",
      "Epoch: 66, val nll=89.61928850446428\n",
      "Epoch: 67, val nll=89.4042236328125\n",
      "saved!\n",
      "Epoch: 68, val nll=89.43634068080357\n",
      "Epoch: 69, val nll=89.45567034040178\n",
      "Epoch: 70, val nll=89.46339076450893\n",
      "Epoch: 71, val nll=89.289755859375\n",
      "saved!\n",
      "Epoch: 72, val nll=89.27838657924107\n",
      "saved!\n",
      "Epoch: 73, val nll=89.40797781808035\n",
      "Epoch: 74, val nll=89.27903738839285\n",
      "Epoch: 75, val nll=89.08249093191964\n",
      "saved!\n",
      "Epoch: 76, val nll=89.24685407366071\n",
      "Epoch: 77, val nll=89.01628278459822\n",
      "saved!\n",
      "Epoch: 78, val nll=89.07181919642858\n",
      "Epoch: 79, val nll=88.91714285714286\n",
      "saved!\n",
      "Epoch: 80, val nll=89.06010323660715\n",
      "Epoch: 81, val nll=89.05834821428572\n",
      "Epoch: 82, val nll=89.10282784598215\n",
      "Epoch: 83, val nll=88.87182756696428\n",
      "saved!\n",
      "Epoch: 84, val nll=88.90016741071429\n",
      "Epoch: 85, val nll=89.00882952008928\n",
      "Epoch: 86, val nll=88.76188197544643\n",
      "saved!\n",
      "Epoch: 87, val nll=88.87893205915178\n",
      "Epoch: 88, val nll=88.56344796316964\n",
      "saved!\n",
      "Epoch: 89, val nll=88.593515625\n",
      "Epoch: 90, val nll=88.91799944196428\n",
      "Epoch: 91, val nll=88.79721400669642\n",
      "Epoch: 92, val nll=88.75043108258929\n",
      "Epoch: 93, val nll=88.97717075892857\n",
      "Epoch: 94, val nll=88.82774204799107\n",
      "FINAL LOSS: nll=85.84557750454418\n"
     ]
    }
   ],
   "source": [
    "D = 64   # input dimension\n",
    "M = 64  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 100 # max. number of epochs\n",
    "max_patience = 5 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped\n",
    "\n",
    "likelihood_type = 'categorical'\n",
    "\n",
    "num_vals = 17\n",
    "\n",
    "kernel = 7\n",
    "\n",
    "net = nn.Sequential(\n",
    "    CausalConv1d(in_channels=1, out_channels=M, dilation=1, kernel_size=kernel, A=True, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=num_vals, dilation=1, kernel_size=kernel, A=False, bias=True))\n",
    "\n",
    "model = ARM(net, D=D, num_vals=num_vals)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))\n",
    "\n",
    "model_label = \"dilation 1-2-4\"\n",
    "experiment = f\"arm-{model_label}_{M}-neurons_{lr:.1e}-lr_{num_epochs}-max-epochs\"\n",
    "\n",
    "result_dir = f'results/{experiment}/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = f'arm-{model_label}'\n",
    "\n",
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)\n",
    "\n",
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)\n",
    "# save training loss curve for further training comparisons.\n",
    "np.savetxt(fname=f\"{result_dir}nll_per_epoch.csv\", X=nll_val)\n",
    "\n",
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARM(\n",
       "  (net): Sequential(\n",
       "    (0): CausalConv1d(\n",
       "      (conv1d): Conv1d(1, 64, kernel_size=(7,), stride=(1,))\n",
       "    )\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): CausalConv1d(\n",
       "      (conv1d): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
       "    )\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): CausalConv1d(\n",
       "      (conv1d): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
       "    )\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): CausalConv1d(\n",
       "      (conv1d): Conv1d(64, 17, kernel_size=(7,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_model = torch.load(f=\"./results/arm-vanilla_64-neurons_1.0e-03-lr_100-max-epochs/arm-vanilla.model\")\n",
    "vanilla_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input=torch.rand(size=(10, 1)) * 16\n",
    "# print(input)\n",
    "vanilla_model.sample(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 100])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input= torch.randn(1,1,100)\n",
    "vanilla_model.net(input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 100])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv  = CausalConv1d(A=True, in_channels=1, out_channels=17, kernel_size=7, dilation=1)\n",
    "conv.forward(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 14])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Conv1d\n",
    "\n",
    "conv  = Conv1d(in_channels=1, out_channels=17, kernel_size=7, dilation=1, padding=0)\n",
    "conv(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n"
     ]
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [17, 1, 1, 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ARM(net\u001b[39m=\u001b[39mConv1d(\u001b[39m1\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m17\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[1;32m/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb Cell 35\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m reduction \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_prob(x)\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39melif\u001b[39;00m reduction \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_prob(x)\u001b[39m.\u001b[39msum())\n",
      "\u001b[1;32m/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb Cell 35\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     mu_d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     log_p \u001b[39m=\u001b[39m log_categorical(x, mu_d, num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_vals, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m log_p\n",
      "\u001b[1;32m/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marbesu/code/misc/intro_dgm/arms/arm_example.ipynb#X52sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     p \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(h, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/mambaforge/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/mambaforge/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [17, 1, 1, 7]"
     ]
    }
   ],
   "source": [
    "model = ARM(net=Conv1d(1, 17, 7))\n",
    "\n",
    "input= torch.randn(17, 1, 7)\n",
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
